---
layout: post
title: Gradient Episodic Memory for Continual Learning
description: "Neural networks that learn from a continuum of data without catastrophic forgetting."
comments: true
---

On March 20, 2018, I gave a talk to the Machine Learning Research Group (MLRG)
at the University of Guelph on continual learning, also called lifelong
learning, which has been a hot research topic in recent years. Here, I reviewed
a super interesting NIPS 2017 paper called <i>Gradient Episodic Memory for
Continual Learning</i> [1] from Facebook AI Research (FAIR). 

<br />
More details coming soon...

<br />
You can download my <a href="https://drive.google.com/file/d/12wPIWhdxkRkkzveYUIJGJHYJnC_sXgvs/view?usp=sharing" target="_blank">Google Slides in PDF</a>.

<br /><b>References</b><br/>
[1] Lopez-Paz, D. and Ranzato, M. Gradient episodic memory for continual learning. In <i>Advances in Neural Information Processing Systems (NIPS) 30</i>, pp. 6467â€“6476. 2017.